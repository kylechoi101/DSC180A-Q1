{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inflow = pd.read_parquet('Week 2/q1-ucsd-inflows.pqt')\n",
    "outflow = pd.read_parquet('Week 2/q1-ucsd-outflows.pqt')\n",
    "\n",
    "outflow_ids = set(outflow[\"prism_consumer_id\"].unique())\n",
    "inflow_ids = set(inflow[\"prism_consumer_id\"].unique())\n",
    "\n",
    "# Consumers in inflow but not in outflow\n",
    "in_not_out = inflow_ids - outflow_ids\n",
    "out_not_in = outflow_ids - inflow_ids\n",
    "#consumers in both inflow and outflow\n",
    "consumers_both = sorted(set(inflow[\"prism_consumer_id\"]).intersection(outflow[\"prism_consumer_id\"]))\n",
    "\n",
    "#80-20 train test split\n",
    "train_ids, test_ids = train_test_split(consumers_both, test_size=0.2, random_state=42)\n",
    "\n",
    "inflow_train = inflow[inflow[\"prism_consumer_id\"].isin(train_ids)]\n",
    "inflow_test  = inflow[inflow[\"prism_consumer_id\"].isin(test_ids)]\n",
    "\n",
    "outflow_train = outflow[outflow[\"prism_consumer_id\"].isin(train_ids)]\n",
    "outflow_test  = outflow[outflow[\"prism_consumer_id\"].isin(test_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'EDUCATION', 1: 'FOOD_AND_BEVERAGES', 2: 'GENERAL_MERCHANDISE', 3: 'GROCERIES', 4: 'MORTGAGE', 5: 'OVERDRAFT', 6: 'PETS', 7: 'RENT', 8: 'TRAVEL'}\n"
     ]
    }
   ],
   "source": [
    "df = outflow_train.copy()\n",
    "df = df[df[\"memo\"] != df[\"category\"]]\n",
    "df[\"posted_date\"] = pd.to_datetime(df[\"posted_date\"])\n",
    "posted = df[\"posted_date\"]\n",
    "\n",
    "df[\"dow\"]   = posted.dt.weekday          # 0–6\n",
    "df[\"month\"] = posted.dt.month           # 1–12\n",
    "\n",
    "# cyclical encodings\n",
    "df[\"dow_sin\"]   = np.sin(2 * np.pi * df[\"dow\"]   / 7)\n",
    "df[\"dow_cos\"]   = np.cos(2 * np.pi * df[\"dow\"]   / 7)\n",
    "df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "amount_train = df[\"amount\"].astype(\"float32\")\n",
    "amount_mean = amount_train.mean()\n",
    "amount_std  = amount_train.std() + 1e-8\n",
    "df[\"amount_z\"] = (amount_train - amount_train.mean()) / (amount_train.std() + 1e-8)\n",
    "extra_cols = [\"amount_z\", \"dow_sin\", \"dow_cos\", \"month_sin\", \"month_cos\"]\n",
    "extra_feats = df[extra_cols].to_numpy(dtype=np.float32)   # shape [N, 5]\n",
    "\n",
    "# Make category dtype and get integer codes\n",
    "df[\"category_code\"] = df[\"category\"].astype(\"category\").cat.codes\n",
    "\n",
    "labels = df[\"category_code\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Optional: store mapping for later interpretation\n",
    "cat_categories = df[\"category\"].astype(\"category\").cat.categories\n",
    "id2cat = dict(enumerate(cat_categories))\n",
    "cat2id = {v: k for k, v in id2cat.items()}\n",
    "\n",
    "print(id2cat)\n",
    "# e.g. {0: 'EDUCATION', 1: 'FOOD_AND_BEVERAGES', ...}\n",
    "memos  = df[\"memo\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665         1\n",
       "666         1\n",
       "671         1\n",
       "686         1\n",
       "690         1\n",
       "           ..\n",
       "534265     33\n",
       "535010     33\n",
       "534994     33\n",
       "534504     33\n",
       "2113388    37\n",
       "Name: memo, Length: 1044281, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"memo\"].apply(lambda x: len(str(x).split())).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.044281e+06\n",
      "mean     5.944968e+00\n",
      "std      4.469744e+00\n",
      "min      1.000000e+00\n",
      "25%      2.000000e+00\n",
      "50%      5.000000e+00\n",
      "75%      1.000000e+01\n",
      "max      3.700000e+01\n",
      "Name: memo, dtype: float64\n",
      "[ 5. 10. 12. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "lengths = df[\"memo\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "print(lengths.describe())\n",
    "print(np.percentile(lengths, [50, 75, 90, 95, 99.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def basic_tokenize(text):\n",
    "    text = str(text).lower()\n",
    "    # very simple: split on non-alphanumeric characters\n",
    "    tokens = re.findall(r\"[a-z0-9]+\", text)\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(texts, min_freq=2, max_size=20000):\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        counter.update(basic_tokenize(t))\n",
    "\n",
    "    # special tokens\n",
    "    itos = [\"<PAD>\", \"<UNK>\"]  # index 0, 1\n",
    "    for tok, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            break\n",
    "        if len(itos) >= max_size:\n",
    "            break\n",
    "        itos.append(tok)\n",
    "\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "# 1) build vocab from all memos\n",
    "vocab, itos = build_vocab(memos, min_freq=2, max_size=20000)\n",
    "pad_idx = vocab[\"<PAD>\"]\n",
    "unk_idx = vocab[\"<UNK>\"]\n",
    "\n",
    "def encode(text, vocab, max_len=17):\n",
    "    tokens = basic_tokenize(text)\n",
    "    ids = [vocab.get(tok, unk_idx) for tok in tokens][:max_len]\n",
    "    # pad if shorter than max_len\n",
    "    if len(ids) < max_len:\n",
    "        ids += [pad_idx] * (max_len - len(ids))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = np.array([encode(m, vocab) for m in memos], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tok_train, X_tok_val, X_extra_train, X_extra_val, y_train, y_val = train_test_split(\n",
    "    X_tokens,\n",
    "    extra_feats,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoPlusDataset(data.Dataset):\n",
    "    def __init__(self, X_tokens, X_extra, y):\n",
    "        self.X_tokens = torch.from_numpy(X_tokens)  # [N, max_len], long\n",
    "        self.X_extra  = torch.from_numpy(X_extra)   # [N, num_extra], float\n",
    "        self.y        = torch.from_numpy(y)         # [N]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_tokens[idx], self.X_extra[idx], self.y[idx]\n",
    "\n",
    "train_ds = MemoPlusDataset(X_tok_train, X_extra_train, y_train)\n",
    "val_ds   = MemoPlusDataset(X_tok_val,   X_extra_val,   y_val)\n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader   = data.DataLoader(val_ds,   batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, d_model]\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoMultiInputTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        num_classes,\n",
    "        num_extra_features,\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=256,\n",
    "        pad_idx=0,\n",
    "        max_len=128,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # ---- Text branch ----\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_len)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,  # so inputs are [B, S, D]\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "        # ---- Numeric branch (amount + date) ----\n",
    "        self.extra_mlp = nn.Sequential(\n",
    "            nn.Linear(num_extra_features, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # ---- Classifier on concatenated features ----\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(2 * d_model, num_classes)\n",
    "\n",
    "    def forward(self, x_tokens, x_extra):\n",
    "        \"\"\"\n",
    "        x_tokens: [batch, seq_len]  (long)\n",
    "        x_extra:  [batch, num_extra_features] (float)\n",
    "        \"\"\"\n",
    "        # Text branch\n",
    "        src = self.embedding(x_tokens) * math.sqrt(self.d_model)  # [B, S, D]\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        # key_padding_mask: True for PAD positions\n",
    "        src_key_padding_mask = (x_tokens == self.pad_idx)         # [B, S]\n",
    "\n",
    "        encoded = self.transformer_encoder(\n",
    "            src,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )  # [B, S, D]\n",
    "\n",
    "        # Mean pool over non-PAD tokens\n",
    "        mask = (~src_key_padding_mask).unsqueeze(-1)              # [B, S, 1]\n",
    "        summed = (encoded * mask).sum(dim=1)                      # [B, D]\n",
    "        counts = mask.sum(dim=1).clamp(min=1)                     # [B, 1]\n",
    "        text_repr = summed / counts                               # [B, D]\n",
    "\n",
    "        # Numeric branch\n",
    "        extra_repr = self.extra_mlp(x_extra)                      # [B, D]\n",
    "\n",
    "        # Concatenate & classify\n",
    "        combined = torch.cat([text_repr, extra_repr], dim=1)      # [B, 2D]\n",
    "        combined = self.dropout(combined)\n",
    "        logits = self.fc_out(combined)                            # [B, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "num_extra_features = len(extra_cols)  # 5 in our example\n",
    "\n",
    "model = MemoMultiInputTransformer(\n",
    "    vocab_size=len(itos),\n",
    "    num_classes=num_classes,\n",
    "    num_extra_features=num_extra_features,\n",
    "    pad_idx=pad_idx,\n",
    "    max_len=37,\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.1740, train_acc=0.9418, val_loss=0.0895, val_acc=0.9712\n",
      "Epoch 2: train_loss=0.0823, train_acc=0.9731, val_loss=0.0708, val_acc=0.9778\n",
      "Epoch 3: train_loss=0.0648, train_acc=0.9789, val_loss=0.0602, val_acc=0.9810\n",
      "Epoch 4: train_loss=0.0561, train_acc=0.9820, val_loss=0.0555, val_acc=0.9827\n",
      "Epoch 5: train_loss=0.0502, train_acc=0.9837, val_loss=0.0535, val_acc=0.9838\n",
      "Epoch 6: train_loss=0.0462, train_acc=0.9849, val_loss=0.0497, val_acc=0.9846\n",
      "Epoch 7: train_loss=0.0431, train_acc=0.9857, val_loss=0.0476, val_acc=0.9856\n",
      "Epoch 8: train_loss=0.0404, train_acc=0.9868, val_loss=0.0501, val_acc=0.9847\n",
      "Epoch 9: train_loss=0.0378, train_acc=0.9876, val_loss=0.0453, val_acc=0.9864\n",
      "Epoch 10: train_loss=0.0357, train_acc=0.9883, val_loss=0.0484, val_acc=0.9854\n"
     ]
    }
   ],
   "source": [
    "def accuracy(logits, y_true):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == y_true).float().mean().item()\n",
    "\n",
    "for epoch in range(10):\n",
    "    # ---- train ----\n",
    "    model.train()\n",
    "    train_loss = train_acc = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for X_tok, X_extra, y_batch in train_loader:\n",
    "        X_tok   = X_tok.to(device)\n",
    "        X_extra = X_extra.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_tok, X_extra)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc  += accuracy(logits.detach(), y_batch)\n",
    "        n_batches  += 1\n",
    "\n",
    "    train_loss /= n_batches\n",
    "    train_acc  /= n_batches\n",
    "\n",
    "    # ---- validation ----\n",
    "    model.eval()\n",
    "    val_loss = val_acc = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_tok, X_extra, y_batch in val_loader:\n",
    "            X_tok   = X_tok.to(device)\n",
    "            X_extra = X_extra.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_tok, X_extra)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc  += accuracy(logits, y_batch)\n",
    "            n_batches += 1\n",
    "\n",
    "    val_loss /= n_batches\n",
    "    val_acc  /= n_batches\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, \"\n",
    "          f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# 1) save model weights\n",
    "torch.save(model.state_dict(), \"memo_transformer_multimodal.pt\")\n",
    "\n",
    "# 2) save preprocessing artifacts\n",
    "artifacts = {\n",
    "    \"vocab\": vocab,          # token -> id\n",
    "    \"itos\": itos,            # id -> token\n",
    "    \"pad_idx\": pad_idx,\n",
    "    \"max_len\": 37,      # 17 or whatever you used\n",
    "    \"extra_cols\": extra_cols,\n",
    "    \"label_classes\": id2cat,   # or your id2cat mapping\n",
    "    \"amount_mean\": float(amount_mean),\n",
    "    \"amount_std\": float(amount_std),\n",
    "}\n",
    "\n",
    "with open(\"memo_transformer_artifacts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(artifacts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoMultiInputTransformer(\n",
       "  (embedding): Embedding(20000, 128, padding_idx=0)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (extra_mlp): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc_out): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "with open(\"memo_transformer_artifacts.pkl\", \"rb\") as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "vocab        = artifacts[\"vocab\"]\n",
    "itos         = artifacts[\"itos\"]\n",
    "pad_idx      = artifacts[\"pad_idx\"]\n",
    "max_len      = artifacts[\"max_len\"]\n",
    "extra_cols   = artifacts[\"extra_cols\"]\n",
    "label_classes = artifacts[\"label_classes\"]\n",
    "amount_mean  = artifacts[\"amount_mean\"]\n",
    "amount_std   = artifacts[\"amount_std\"]\n",
    "\n",
    "model = MemoMultiInputTransformer(\n",
    "    vocab_size=len(itos),\n",
    "    num_classes=len(label_classes),\n",
    "    num_extra_features=len(extra_cols),\n",
    "    pad_idx=pad_idx,\n",
    "    max_len=max_len,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"memo_transformer_multimodal.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model  # your trained MemoMultiInputTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class MemoTextEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        num_layers=2,\n",
    "        dim_feedforward=256,\n",
    "        pad_idx=0,\n",
    "        max_len=128,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_len)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x_tokens):\n",
    "        \"\"\"\n",
    "        x_tokens: [batch, seq_len] of token ids\n",
    "        returns:  [batch, d_model] pooled text embedding\n",
    "        \"\"\"\n",
    "        src = self.embedding(x_tokens) * math.sqrt(self.d_model)  # [B, S, D]\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        src_key_padding_mask = (x_tokens == self.pad_idx)         # [B, S]\n",
    "\n",
    "        encoded = self.transformer_encoder(\n",
    "            src,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )  # [B, S, D]\n",
    "\n",
    "        # mean pool over non-PAD tokens\n",
    "        mask = (~src_key_padding_mask).unsqueeze(-1)              # [B, S, 1]\n",
    "        summed = (encoded * mask).sum(dim=1)                      # [B, D]\n",
    "        counts = mask.sum(dim=1).clamp(min=1)                     # [B, 1]\n",
    "        text_repr = summed / counts                               # [B, D]\n",
    "        return text_repr\n",
    "text_encoder = MemoTextEncoder(\n",
    "    vocab_size=len(itos),\n",
    "    d_model=128,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=256,\n",
    "    pad_idx=pad_idx,\n",
    "    max_len=37,\n",
    ").to(device)\n",
    "\n",
    "text_encoder.embedding.load_state_dict(clf.embedding.state_dict())\n",
    "text_encoder.pos_encoder.load_state_dict(clf.pos_encoder.state_dict())\n",
    "text_encoder.transformer_encoder.load_state_dict(clf.transformer_encoder.state_dict())\n",
    "\n",
    "text_encoder.eval()\n",
    "for p in text_encoder.parameters():\n",
    "    p.requires_grad = False  # freeze like MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = outflow_test.copy()\n",
    "\n",
    "# If you filtered this way during training, do the SAME filter here\n",
    "df = df[df[\"memo\"] != df[\"category\"]].reset_index(drop=True)\n",
    "\n",
    "# --- datetime features ---\n",
    "df[\"posted_date\"] = pd.to_datetime(df[\"posted_date\"])\n",
    "posted = df[\"posted_date\"]\n",
    "\n",
    "df[\"dow\"]   = posted.dt.weekday\n",
    "df[\"month\"] = posted.dt.month\n",
    "\n",
    "df[\"dow_sin\"]   = np.sin(2 * np.pi * df[\"dow\"]   / 7)\n",
    "df[\"dow_cos\"]   = np.cos(2 * np.pi * df[\"dow\"]   / 7)\n",
    "df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "# --- amount scaling: USE TRAIN MEAN/STDEV ---\n",
    "amount = df[\"amount\"].astype(\"float32\")\n",
    "df[\"amount_z\"] = (amount - amount_mean) / (amount_std + 1e-8)\n",
    "\n",
    "extra_cols = [\"amount_z\", \"dow_sin\", \"dow_cos\", \"month_sin\", \"month_cos\"]\n",
    "X_extra_test = df[extra_cols].to_numpy(dtype=np.float32)   # [N_test, 5]\n",
    "# Use the SAME label encoder 'le' from training\n",
    "y_test = np.array([cat2id[c] for c in df[\"category\"].values], dtype=np.int64)\n",
    "memos_test = df[\"memo\"].astype(str).tolist()\n",
    "X_tokens_test = np.array(\n",
    "    [encode(m, vocab, max_len=17) for m in memos_test],\n",
    "    dtype=np.int64\n",
    ")\n",
    "test_ds = MemoPlusDataset(X_tokens_test, X_extra_test, y_test)\n",
    "test_loader = data.DataLoader(test_ds, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: loss=0.1761, acc=0.9532\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "n_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_tok, X_extra, y_batch in test_loader:\n",
    "        X_tok   = X_tok.to(device)\n",
    "        X_extra = X_extra.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(X_tok, X_extra)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        test_acc  += (preds == y_batch).float().mean().item()\n",
    "        n_batches += 1\n",
    "\n",
    "test_loss /= n_batches\n",
    "test_acc  /= n_batches\n",
    "print(f\"TEST: loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoMultiInputTransformer(\n",
       "  (embedding): Embedding(20000, 128, padding_idx=0)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (extra_mlp): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc_out): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8988 | Val accuracy: 0.8986\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Device & trained transformer\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 'memo_model' should be your trained MemoMultiInputTransformer\n",
    "memo_model = model.to(device).eval()  # frozen encoder for now\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Use YOUR transformer as embedder\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def embed_text(texts, batch_size=256):\n",
    "    \"\"\"\n",
    "    texts: list[str]\n",
    "    returns: np.array of shape [N, d_model] from your memo transformer\n",
    "    \"\"\"\n",
    "    # tokenize with your vocab/encode\n",
    "    token_ids = np.array(\n",
    "        [encode(str(t), vocab, max_len=max_len) for t in texts],\n",
    "        dtype=np.int64\n",
    "    )\n",
    "    ds = torch.utils.data.TensorDataset(torch.from_numpy(token_ids))\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_embs = []\n",
    "    memo_model.eval()\n",
    "    for (xb,) in dl:\n",
    "        xb = xb.to(device)                     # [B, S]\n",
    "\n",
    "        # ---- text branch from MemoMultiInputTransformer ----\n",
    "        src = memo_model.embedding(xb) * math.sqrt(memo_model.d_model)  # [B, S, D]\n",
    "        src = memo_model.pos_encoder(src)                                # [B, S, D]\n",
    "\n",
    "        src_key_padding_mask = (xb == memo_model.pad_idx)                # [B, S]\n",
    "\n",
    "        enc_out = memo_model.transformer_encoder(\n",
    "            src,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )                                                                 # [B, S, D]\n",
    "\n",
    "        # mean pool over non-PAD tokens\n",
    "        mask = (~src_key_padding_mask).unsqueeze(-1)                      # [B, S, 1]\n",
    "        summed = (enc_out * mask).sum(dim=1)                              # [B, D]\n",
    "        counts = mask.sum(dim=1).clamp(min=1)                             # [B, 1]\n",
    "        pooled = summed / counts                                          # [B, D]\n",
    "\n",
    "        all_embs.append(pooled.cpu())\n",
    "\n",
    "    embs = torch.cat(all_embs, dim=0)                                     # [N, D]\n",
    "    return embs.numpy().astype(\"float32\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build feature matrix [memo_emb | log1p(amount) | dow | month]\n",
    "# -----------------------------\n",
    "df = outflow_train.dropna(subset=['memo','category','amount','posted_date']).copy()\n",
    "df['posted_date'] = pd.to_datetime(df['posted_date'], errors='coerce')\n",
    "df = df.dropna(subset=['posted_date'])\n",
    "\n",
    "# (optional but good) drop ultra-rare categories (count < 2) to avoid stratified split error\n",
    "vc = df['category'].value_counts()\n",
    "keep_cats = vc[vc >= 2].index\n",
    "df = df[df['category'].isin(keep_cats)].copy()\n",
    "\n",
    "# memo embeddings from YOUR transformer\n",
    "memo_emb = embed_text(df['memo'].astype(str).tolist())         # [N, D]\n",
    "\n",
    "# numeric features\n",
    "posted = df[\"posted_date\"]\n",
    "\n",
    "df[\"dow\"]   = posted.dt.weekday          # 0–6\n",
    "df[\"month\"] = posted.dt.month            # 1–12\n",
    "\n",
    "amt       = np.log1p(df[\"amount\"].astype(float).to_numpy())[:, None]                 # [N,1]\n",
    "dow_sin   = np.sin(2 * np.pi * df[\"dow\"].to_numpy()   / 7.0)[:, None]                # [N,1]\n",
    "dow_cos   = np.cos(2 * np.pi * df[\"dow\"].to_numpy()   / 7.0)[:, None]                # [N,1]\n",
    "month_sin = np.sin(2 * np.pi * df[\"month\"].to_numpy() / 12.0)[:, None]               # [N,1]\n",
    "month_cos = np.cos(2 * np.pi * df[\"month\"].to_numpy() / 12.0)[:, None]               # [N,1]\n",
    "\n",
    "num_feats = np.concatenate(\n",
    "    [amt, dow_sin, dow_cos, month_sin, month_cos],\n",
    "    axis=1\n",
    ").astype(\"float32\")   # shape [N, 5]\n",
    "\n",
    "# final feature matrix\n",
    "X_np = np.concatenate([memo_emb, num_feats], axis=1).astype(\"float32\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Labels (category → int)\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "y_np = le.fit_transform(df['category'].astype(str)).astype(\"int64\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Train/val split for meta loop\n",
    "# -----------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_np, y_np, test_size=0.1, random_state=42, stratify=y_np\n",
    ")\n",
    "\n",
    "X_t  = torch.from_numpy(X_train).to(device)\n",
    "y_t  = torch.from_numpy(y_train).to(device)\n",
    "Xv_t = torch.from_numpy(X_val).to(device)\n",
    "yv_t = torch.from_numpy(y_val).to(device)\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(X_t, y_t)\n",
    "val_ds   = torch.utils.data.TensorDataset(Xv_t, yv_t)\n",
    "\n",
    "loader     = torch.utils.data.DataLoader(train_ds, batch_size=512, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds,   batch_size=512, shuffle=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) MLP classifier (Categorio_V3)\n",
    "# -----------------------------\n",
    "class Categorio_V3(nn.Module):\n",
    "    def __init__(self, d_in, d_out, width=512, p=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, width), nn.ReLU(), nn.Dropout(p),\n",
    "            nn.Linear(width, width), nn.ReLU(), nn.Dropout(p),\n",
    "            nn.Linear(width, d_out)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model_3 = Categorio_V3(\n",
    "    d_in=X_np.shape[1],\n",
    "    d_out=len(le.classes_),\n",
    "    width=512,\n",
    "    p=0.2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_3.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# class weights (inverse frequency)\n",
    "classes, counts = np.unique(y_np, return_counts=True)\n",
    "class_weights = torch.tensor(1.0 / counts, dtype=torch.float32)\n",
    "class_weights = class_weights / class_weights.sum() * len(classes)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Meta-weighting helpers\n",
    "# -----------------------------\n",
    "val_iter = itertools.cycle(val_loader)  # endless cycle of validation mini-batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_val_loss(m, xv, yv):\n",
    "    m.eval()\n",
    "    logits_v = m(xv)\n",
    "    return loss_fn(logits_v, yv).detach()\n",
    "\n",
    "def meta_weight_for_batch(model_mlp, xb, yb, xv, yv, inner_lr=5e-4, sharpness=10.0):\n",
    "    \"\"\"\n",
    "    Make a fast copy of the model, apply one SGD-like step on (xb, yb),\n",
    "    then measure Δval = L_after - L_before. Convert to weight via sigmoid(-sharpness * Δval).\n",
    "    \"\"\"\n",
    "    # 1) validation loss before\n",
    "    with torch.no_grad():\n",
    "        val_before = eval_val_loss(model_mlp, xv, yv)\n",
    "\n",
    "    # 2) clone parameters\n",
    "    probe = deepcopy(model_mlp).to(device)\n",
    "    probe.train()\n",
    "    probe.zero_grad(set_to_none=True)\n",
    "    logits = probe(xb)\n",
    "    train_loss = loss_fn(logits, yb)\n",
    "    grads = torch.autograd.grad(train_loss, probe.parameters(), create_graph=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p, g in zip(probe.parameters(), grads):\n",
    "            if g is not None:\n",
    "                p.add_(-inner_lr * g)\n",
    "\n",
    "    # 3) validation loss after\n",
    "    with torch.no_grad():\n",
    "        val_after = eval_val_loss(probe, xv, yv)\n",
    "\n",
    "    # 4) improvement → weight in (0,1)\n",
    "    delta = (val_after - val_before).clamp(min=-5.0, max=5.0)\n",
    "    w = torch.sigmoid(-sharpness * delta).item()\n",
    "    return float(w)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Training loop with meta-weighted losses\n",
    "# -----------------------------\n",
    "model_3.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        xv, yv = next(val_iter)\n",
    "        xv = xv.to(device); yv = yv.to(device)\n",
    "\n",
    "        # meta weight for this batch\n",
    "        w_batch = meta_weight_for_batch(model_3, xb, yb, xv, yv,\n",
    "                                        inner_lr=5e-4, sharpness=10.0)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model_3(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        (loss * w_batch).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Final train / val accuracy\n",
    "# -----------------------------\n",
    "model_3.eval()\n",
    "with torch.inference_mode():\n",
    "    logits_tr = model_3(X_t)\n",
    "    preds_tr = logits_tr.argmax(dim=1)\n",
    "    acc_tr = (preds_tr == y_t).float().mean().item()\n",
    "\n",
    "    logits_va = model_3(Xv_t)\n",
    "    preds_va = logits_va.argmax(dim=1)\n",
    "    acc_va = (preds_va == yv_t).float().mean().item()\n",
    "\n",
    "print(f\"Train accuracy: {acc_tr:.4f} | Val accuracy: {acc_va:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows after cleaning: 524896\n",
      "X_test shape: (524896, 133)\n",
      "y_test shape: (524896,)\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Start from outflow_test, same cleaning as train ---\n",
    "df_te = outflow_test.dropna(subset=['memo','category','amount','posted_date']).copy()\n",
    "df_te['posted_date'] = pd.to_datetime(df_te['posted_date'], errors='coerce')\n",
    "df_te = df_te.dropna(subset=['posted_date'])\n",
    "\n",
    "# keep only categories seen in training (le.classes_)\n",
    "df_te = df_te[df_te['category'].isin(le.classes_)].copy()\n",
    "\n",
    "print(\"Test rows after cleaning:\", len(df_te))\n",
    "\n",
    "# --- 2) Memo embeddings from YOUR transformer ---\n",
    "memos_te = df_te['memo'].astype(str).tolist()\n",
    "memo_emb_te = embed_text(memos_te)          # shape [N_te, D]\n",
    "\n",
    "# --- 3) Numeric features: log1p(amount), dow/month cyclical ---\n",
    "posted_te = df_te[\"posted_date\"]\n",
    "\n",
    "df_te[\"dow\"]   = posted_te.dt.weekday      # 0–6\n",
    "df_te[\"month\"] = posted_te.dt.month        # 1–12\n",
    "\n",
    "amt_te       = np.log1p(df_te[\"amount\"].astype(float).to_numpy())[:, None]\n",
    "dow_sin_te   = np.sin(2 * np.pi * df_te[\"dow\"].to_numpy()   / 7.0)[:, None]\n",
    "dow_cos_te   = np.cos(2 * np.pi * df_te[\"dow\"].to_numpy()   / 7.0)[:, None]\n",
    "month_sin_te = np.sin(2 * np.pi * df_te[\"month\"].to_numpy() / 12.0)[:, None]\n",
    "month_cos_te = np.cos(2 * np.pi * df_te[\"month\"].to_numpy() / 12.0)[:, None]\n",
    "\n",
    "num_feats_te = np.concatenate(\n",
    "    [amt_te, dow_sin_te, dow_cos_te, month_sin_te, month_cos_te],\n",
    "    axis=1\n",
    ").astype(\"float32\")                         # [N_te, 5]\n",
    "\n",
    "# --- 4) Final test feature matrix ---\n",
    "X_test_np = np.concatenate([memo_emb_te, num_feats_te], axis=1).astype(\"float32\")\n",
    "\n",
    "# --- 5) Test labels using SAME LabelEncoder ---\n",
    "y_test_np = le.transform(df_te['category'].astype(str)).astype(\"int64\")\n",
    "\n",
    "print(\"X_test shape:\", X_test_np.shape)\n",
    "print(\"y_test shape:\", y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: loss=147.7558, acc=0.8764\n"
     ]
    }
   ],
   "source": [
    "X_test_t = torch.from_numpy(X_test_np).to(device)\n",
    "y_test_t = torch.from_numpy(y_test_np).to(device)\n",
    "\n",
    "model_3.eval()\n",
    "with torch.inference_mode():\n",
    "    logits_te = model_3(X_test_t)\n",
    "    preds_te = logits_te.argmax(dim=1)\n",
    "\n",
    "    acc_te = (preds_te == y_test_t).float().mean().item()\n",
    "    test_loss = loss_fn(logits_te, y_test_t).item()\n",
    "\n",
    "print(f\"TEST: loss={test_loss:.4f}, acc={acc_te:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
